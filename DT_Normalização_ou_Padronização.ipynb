{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/renatamontanhana/normalizacao_padronizacao_dados/blob/main/DT_Normaliza%C3%A7%C3%A3o_ou_Padroniza%C3%A7%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZVCagpZvZfE"
      },
      "source": [
        "![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTK4gQ9nhwHHaSXMHpeggWg7twwMCgb877smkRmtkmDeDoGF9Z6&usqp=CAU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbPb0q01k11H"
      },
      "source": [
        "##<font color='GreeN'>Dicas e Truques de Ciência de Dados </font>\n",
        "\n",
        "##<font color='black'>Fase de Pré-Processamamento dos Dados</font>\n",
        "\n",
        "### <font color='grey'>Normalização e Padronização dos Dados</font>\n",
        "\n",
        "### <font color='blUE'> O que é.... e Quando Usar....</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwDl_24l6XGh"
      },
      "source": [
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "im = Image.open(\"/content/5 Fases.PNG\")\n",
        "im.show()\n",
        "im\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN5MxQyGWB6K"
      },
      "source": [
        "# <font color='black'>3° Pré-Processamento - Preparando os Dados para Machine Learning</font>\n",
        "\n",
        "Muitos algoritmos esperam receber os dados em um formato específico. É seu trabalho preparar os dados em uma estrutura que seja adequada ao algoritmo que você está utilizando.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBJPX6LGS7Sb"
      },
      "source": [
        "###Normalização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbLotZBxS7Sc"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxCgxiIWS7Sd"
      },
      "source": [
        "E uma das primeiras tarefas dentro do pré-processamento, é colocar seus dados na mesma escala. Muitos algoritmos de Machine Learning vão se beneficiar disso e produzir resultados melhores. Esta etapa também é chamada de normalização e significa colocar os dados em uma escala com range entre 0 e 1. Isso é útil para a otimização, sendo usado no core dos algoritmos de Machine Learning, como gradient descent. Isso também é útil para algoritmos como regressão e redes neurais e algoritmos que usam medidas de distância, como KNN. O scikit-learn possui uma função para esta etapa, chamada MinMaxScaler()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR_VDPzWS7Sd",
        "outputId": "34cbbe45-2701-475c-96de-23b7d249c4ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Transformando os dados para a mesma escala (entre 0 e 1)\n",
        "\n",
        "# Import dos módulos\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Carregando os dados\n",
        "arquivo = 'pima-data.csv'\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dados = read_csv(arquivo, names = colunas)\n",
        "array = dados.values\n",
        "\n",
        "# Separando o array em componentes de input (X) e output (Y)\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "# Gerando a nova escala (normalizando os dados)\n",
        "scaler = MinMaxScaler(feature_range = (0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "\n",
        "# Sumarizando os dados transformados\n",
        "print(\"Dados Originais: \\n\\n\", dados.values)\n",
        "print(\"\\nDados Normalizados: \\n\\n\", rescaledX[0:5,:])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados Originais: \n",
            "\n",
            " [[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
            " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
            " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
            " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
            " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n",
            "\n",
            "Dados Normalizados: \n",
            "\n",
            " [[0.35294118 0.74371859 0.59016393 0.35353535 0.         0.50074516\n",
            "  0.23441503 0.48333333]\n",
            " [0.05882353 0.42713568 0.54098361 0.29292929 0.         0.39642325\n",
            "  0.11656704 0.16666667]\n",
            " [0.47058824 0.91959799 0.52459016 0.         0.         0.34724292\n",
            "  0.25362938 0.18333333]\n",
            " [0.05882353 0.44723618 0.54098361 0.23232323 0.11111111 0.41877794\n",
            "  0.03800171 0.        ]\n",
            " [0.         0.68844221 0.32786885 0.35353535 0.19858156 0.64232489\n",
            "  0.94363792 0.2       ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40DhT47yS7Sl"
      },
      "source": [
        "### Padronização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mBVo1buS7Sm"
      },
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sSVDoheS7Sn"
      },
      "source": [
        "Padronização é a técnica para transformar os atributos com distribuição Gaussiana (normal) e diferentes médias e desvios padrão em uma distribuição Gaussiana com a média igual a 0 e desvio padrão igual a 1. Isso é útil para algoritmos que esperam que os dados estejam com uma distribuição Gaussiana, como regressão linear, regressão logística e linear discriminant analysis. Funciona bem quando os dados já estão na mesma escala. O scikit-learn possui uma função para esta etapa, chamada StandardScaler()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5NCZwSwS7Sn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6088d2-9fd8-40b5-8a57-e9dda55749ef"
      },
      "source": [
        "# Padronizando os dados (0 para a média, 1 para o desvio padrão)\n",
        "\n",
        "# Import dos módulos\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Carregando os dados\n",
        "arquivo = 'pima-data.csv'\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dados = read_csv(arquivo, names = colunas)\n",
        "array = dados.values\n",
        "\n",
        "# Separando o array em componentes de input e output\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "# Gerando o novo padrão\n",
        "scaler = StandardScaler().fit(X)\n",
        "standardX = scaler.transform(X)\n",
        "\n",
        "# Sumarizando os dados transformados\n",
        "print(\"Dados Originais: \\n\\n\", dados.values)\n",
        "print(\"\\nDados Padronizados: \\n\\n\", standardX[0:5,:])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados Originais: \n",
            "\n",
            " [[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
            " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
            " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
            " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
            " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n",
            "\n",
            "Dados Padronizados: \n",
            "\n",
            " [[ 0.63994726  0.84832379  0.14964075  0.90726993 -0.69289057  0.20401277\n",
            "   0.46849198  1.4259954 ]\n",
            " [-0.84488505 -1.12339636 -0.16054575  0.53090156 -0.69289057 -0.68442195\n",
            "  -0.36506078 -0.19067191]\n",
            " [ 1.23388019  1.94372388 -0.26394125 -1.28821221 -0.69289057 -1.10325546\n",
            "   0.60439732 -0.10558415]\n",
            " [-0.84488505 -0.99820778 -0.16054575  0.15453319  0.12330164 -0.49404308\n",
            "  -0.92076261 -1.04154944]\n",
            " [-1.14185152  0.5040552  -1.50468724  0.90726993  0.76583594  1.4097456\n",
            "   5.4849091  -0.0204964 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsAQvrKP3ovn"
      },
      "source": [
        "# Resultado da Máquina Preditiva Sem Redimensionamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJNr928JS7Ua",
        "outputId": "b75ec391-85d4-4eef-f7d5-b9276b451814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Import dos módulos\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Carregando os dados\n",
        "arquivo = 'pima-data.csv'\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dados = read_csv(arquivo, names = colunas)\n",
        "array = dados.values\n",
        "\n",
        "# Separando o array em componentes de input e output\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "# Definindo os valores para o número de folds\n",
        "num_folds = 10\n",
        "random_state = 7\n",
        "\n",
        "# Separando os dados em folds\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=random_state)\n",
        "\n",
        "# Criando o modelo\n",
        "modelo = KNeighborsClassifier()\n",
        "\n",
        "# Cross Validation\n",
        "results = cross_val_score(modelo, X, Y, cv = kfold)\n",
        "\n",
        "# Print do resultado\n",
        "print(\"Acurácia: %.3f\" % (results.mean() * 100))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 71.099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwG6iFZQ3_q6"
      },
      "source": [
        "# Resultado Com Padronização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdPdx-Eh4GaX"
      },
      "source": [
        "# Padronizando os dados (0 para a média, 1 para o desvio padrão)\n",
        "\n",
        "# Import dos módulos\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Carregando os dados\n",
        "arquivo = 'pima-data.csv'\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dados = read_csv(arquivo, names = colunas)\n",
        "array = dados.values\n",
        "\n",
        "# Separando o array em componentes de input e output\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "# Gerando o novo padrão\n",
        "scaler = StandardScaler().fit(X)\n",
        "standardX = scaler.transform(X)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgjNN1Xd4slz"
      },
      "source": [
        "# Definindo os valores para o número de folds\n",
        "num_folds = 10\n",
        "random_state = 7\n",
        "\n",
        "# Separando os dados em folds\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=random_state)\n",
        "\n",
        "# Criando o modelo\n",
        "modelo = KNeighborsClassifier()\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL1CkMKW4vrA"
      },
      "source": [
        "# Cross Validation\n",
        "results = cross_val_score(modelo, standardX, Y, cv = kfold)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDd4JpIS4ys_",
        "outputId": "ef4825e9-e9f2-437e-d172-b19a59944fa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print do resultado\n",
        "print(\"Acurácia: %.3f\" % (results.mean() * 100))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 73.966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRyvyyEN5Hz0"
      },
      "source": [
        "# Resultado Com Normalização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDghkjtc5SHN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c1941e-c2c6-4245-990c-05503fb9fd5e"
      },
      "source": [
        "# Transformando os dados para a mesma escala (entre 0 e 1)\n",
        "\n",
        "# Import dos módulos\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Carregando os dados\n",
        "arquivo = 'pima-data.csv'\n",
        "colunas = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dados = read_csv(arquivo, names = colunas)\n",
        "array = dados.values\n",
        "\n",
        "# Separando o array em componentes de input (X) e output (Y)\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "# Gerando a nova escala (normalizando os dados)\n",
        "scaler = MinMaxScaler(feature_range = (0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "\n",
        "# Sumarizando os dados transformados\n",
        "print(\"Dados Originais: \\n\\n\", dados.values)\n",
        "print(\"\\nDados Normalizados: \\n\\n\", rescaledX[0:5,:])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados Originais: \n",
            "\n",
            " [[  6.    148.     72.    ...   0.627  50.      1.   ]\n",
            " [  1.     85.     66.    ...   0.351  31.      0.   ]\n",
            " [  8.    183.     64.    ...   0.672  32.      1.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...   0.245  30.      0.   ]\n",
            " [  1.    126.     60.    ...   0.349  47.      1.   ]\n",
            " [  1.     93.     70.    ...   0.315  23.      0.   ]]\n",
            "\n",
            "Dados Normalizados: \n",
            "\n",
            " [[0.35294118 0.74371859 0.59016393 0.35353535 0.         0.50074516\n",
            "  0.23441503 0.48333333]\n",
            " [0.05882353 0.42713568 0.54098361 0.29292929 0.         0.39642325\n",
            "  0.11656704 0.16666667]\n",
            " [0.47058824 0.91959799 0.52459016 0.         0.         0.34724292\n",
            "  0.25362938 0.18333333]\n",
            " [0.05882353 0.44723618 0.54098361 0.23232323 0.11111111 0.41877794\n",
            "  0.03800171 0.        ]\n",
            " [0.         0.68844221 0.32786885 0.35353535 0.19858156 0.64232489\n",
            "  0.94363792 0.2       ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpQLq7I95V-8"
      },
      "source": [
        "# Definindo os valores para o número de folds\n",
        "num_folds = 10\n",
        "random_state = 7\n",
        "\n",
        "# Separando os dados em folds\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=random_state)\n",
        "\n",
        "# Criando o modelo\n",
        "modelo = KNeighborsClassifier()\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYCytxWj5V_I"
      },
      "source": [
        "# Cross Validation\n",
        "results = cross_val_score(modelo, rescaledX, Y, cv = kfold)\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1_edRCF5V_N",
        "outputId": "d4640b97-3304-4537-f022-8f82ad4625d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print do resultado\n",
        "print(\"Acurácia: %.3f\" % (results.mean() * 100))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia: 73.835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I55V5QE66Lg"
      },
      "source": [
        "# Valeu!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r1o8LDDzj16"
      },
      "source": [
        "### #Instagram - Ciencia dos Dados <a href=\"http://instagram.com/cienciadosdados\">instagram.com/cienciadosdados</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHRHbHwmfFEy"
      },
      "source": [
        "### #**Telegram** - Scripts e Datasets - Comunidade Telegram <a href=\"https://t.me/cienciadosdadosraiz\">https://t.me/cienciadosdadosraiz</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCGIEsSrKG66"
      },
      "source": [
        "### #Facebook - Ciencia dos Dados <a href=\"http://facebook.com/cienciadosdadosbr\">facebook.com/cienciadosdadosbr</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThxYRK6DfJ3f"
      },
      "source": [
        "### #YouTube - Mais Aulas como essa no YouTube <a href=\"https://www.youtube.com/watch?v=IaIc5oHd3II&t=1569s\">https://www.youtube.com/watch?v=IaIc5oHd3II&t=1569s</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RhZt67dz5Ea"
      },
      "source": [
        "### #Portal Gratuito - Ciencia dos Dados <a href=\"http://cienciadosdados.com\">cienciadosdados.com</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkP_tsvJ3m_K"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzBOQGCpYHus",
        "outputId": "86ee0557-3f58-4eb7-8cc4-cafefc148fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "from IPython.core.display import HTML\n",
        "HTML('<iframe width=\"380\" height=\"200\" src=\"https://www.youtube.com/embed/U7VJljqHwjY?list=PLeR2Gm6UuDXr14EhmTpJ9kdqgG0z2YB-w\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"380\" height=\"200\" src=\"https://www.youtube.com/embed/U7VJljqHwjY?list=PLeR2Gm6UuDXr14EhmTpJ9kdqgG0z2YB-w\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}